import streamlit as st
import json
import xml.etree.ElementTree as ET
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots
import jsonschema
import xmlschema
from datetime import datetime
import hashlib
import time
import re
from typing import Dict, List, Tuple, Any, Optional
from dataclasses import dataclass
from pathlib import Path
import networkx as nx

# –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è —Å—Ç–æ—Ä—ñ–Ω–∫–∏
st.set_page_config(
    page_title="SBOM Validator",
    page_icon="üõ°Ô∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# CSS —Å—Ç–∏–ª—ñ
st.markdown("""
<style>
    .main-header {
        background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
        padding: 2rem;
        border-radius: 10px;
        color: white;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    .metric-card {
        background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
        padding: 1rem;
        border-radius: 10px;
        border: 1px solid #e0e0e0;
        margin-bottom: 1rem;
    }
    
    .quality-score {
        font-size: 3rem;
        font-weight: bold;
        text-align: center;
    }
    
    .quality-excellent { color: #28a745; }
    .quality-good { color: #17a2b8; }
    .quality-warning { color: #ffc107; }
    .quality-poor { color: #dc3545; }
    
    .error-box {
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    
    .warning-box {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        border-radius: 5px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
    
    .success-box {
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        padding: 1rem;
        margin: 0.5rem 0;
    }
</style>
""", unsafe_allow_html=True)

@dataclass
class ValidationResult:
    is_valid: bool
    format_type: str
    version: str
    data_type: str
    errors: List[str]
    warnings: List[str]
    quality_score: int
    analysis: Dict[str, Any]
    processing_time: float

class EnhancedSBOMValidator:
    """–ü–æ–∫—Ä–∞—â–µ–Ω–∏–π SBOM –≤–∞–ª—ñ–¥–∞—Ç–æ—Ä –∑ auto-detection —Ç–∞ —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–º –∞–Ω–∞–ª—ñ–∑–æ–º"""
    
    def __init__(self):
        self.supported_formats = {
            'spdx': {
                '2.3': {'json': True, 'xml': False},
                '3.0': {'json': True, 'xml': False}
            },
            'cyclonedx': {
                '1.3': {'json': True, 'xml': True},
                '1.4': {'json': True, 'xml': True},
                '1.5': {'json': True, 'xml': True},
                '1.6': {'json': True, 'xml': True}
            }
        }
        
        # SPDX —Å—Ö–µ–º–∏ (—Å–ø—Ä–æ—â–µ–Ω—ñ –¥–ª—è –¥–µ–º–æ–Ω—Å—Ç—Ä–∞—Ü—ñ—ó)
        self.spdx_schema_2_3 = {
            "type": "object",
            "required": ["spdxVersion", "SPDXID", "name", "dataLicense"],
            "properties": {
                "spdxVersion": {"type": "string", "pattern": "^SPDX-2\\.3$"},
                "SPDXID": {"type": "string", "pattern": "^SPDXRef-DOCUMENT$"},
                "name": {"type": "string"},
                "dataLicense": {"type": "string"},
                "packages": {"type": "array"}
            }
        }
        
        self.spdx_schema_3_0 = {
            "type": "object",
            "required": ["spdxVersion", "SPDXID", "name", "dataLicense"],
            "properties": {
                "spdxVersion": {"type": "string", "pattern": "^SPDX-3\\.0$"},
                "SPDXID": {"type": "string"},
                "name": {"type": "string"},
                "dataLicense": {"type": "string"},
                "packages": {"type": "array"}
            }
        }
        
        # CycloneDX —Å—Ö–µ–º–∏
        self.cyclonedx_schema = {
            "type": "object",
            "required": ["bomFormat", "specVersion"],
            "properties": {
                "bomFormat": {"type": "string", "const": "CycloneDX"},
                "specVersion": {"type": "string"},
                "version": {"type": "integer"},
                "components": {"type": "array"},
                "metadata": {"type": "object"}
            }
        }
    
    def detect_sbom_format(self, content: str, filename: str = "") -> Tuple[str, str, str]:
        """–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ñ–æ—Ä–º–∞—Ç—É SBOM"""
        try:
            # –°–ø–æ—á–∞—Ç–∫—É –ø–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ JSON
            if content.strip().startswith('{'):
                data = json.loads(content)
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ SPDX
                if "spdxVersion" in data:
                    version = data.get("spdxVersion", "").replace("SPDX-", "")
                    return "spdx", version, "json"
                
                # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ CycloneDX
                elif "bomFormat" in data and data["bomFormat"] == "CycloneDX":
                    version = data.get("specVersion", "1.4")
                    return "cyclonedx", version, "json"
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ XML
            elif content.strip().startswith('<'):
                root = ET.fromstring(content)
                
                # CycloneDX XML
                if 'cyclonedx' in root.tag.lower() or 'bom' in root.tag.lower():
                    version = root.get('version', '1.4')
                    return "cyclonedx", version, "xml"
                
                # SPDX XML (—Ä—ñ–¥–∫–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è)
                elif 'spdx' in root.tag.lower():
                    return "spdx", "2.3", "xml"
            
            # –ü–µ—Ä–µ–≤—ñ—Ä—è—î–º–æ –∑–∞ –Ω–∞–∑–≤–æ—é —Ñ–∞–π–ª—É
            if filename:
                if 'spdx' in filename.lower():
                    return "spdx", "2.3", "json"
                elif 'cyclone' in filename.lower() or 'sbom' in filename.lower():
                    return "cyclonedx", "1.4", "json"
        
        except Exception:
            pass
        
        return "unknown", "unknown", "unknown"
    
    def validate_schema(self, data: Any, format_type: str, version: str, data_type: str) -> Tuple[bool, List[str]]:
        """–í–∞–ª—ñ–¥–∞—Ü—ñ—è —Å—Ö–µ–º–∏"""
        errors = []
        
        try:
            if format_type == "spdx":
                if version == "2.3":
                    jsonschema.validate(data, self.spdx_schema_2_3)
                elif version == "3.0":
                    jsonschema.validate(data, self.spdx_schema_3_0)
                else:
                    errors.append(f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∞ –≤–µ—Ä—Å—ñ—è SPDX: {version}")
            
            elif format_type == "cyclonedx":
                if data_type == "json":
                    jsonschema.validate(data, self.cyclonedx_schema)
                elif data_type == "xml":
                    # –î–ª—è XML –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î–º–æ –±–∞–∑–æ–≤—É –ø–µ—Ä–µ–≤—ñ—Ä–∫—É
                    if not isinstance(data, ET.Element):
                        errors.append("–ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–∏–π XML —Ñ–æ—Ä–º–∞—Ç")
            
            else:
                errors.append(f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ñ–æ—Ä–º–∞—Ç: {format_type}")
        
        except jsonschema.ValidationError as e:
            errors.append(f"–ü–æ–º–∏–ª–∫–∞ —Å—Ö–µ–º–∏: {e.message}")
        except Exception as e:
            errors.append(f"–ü–æ–º–∏–ª–∫–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó: {str(e)}")
        
        return len(errors) == 0, errors
    
    def business_rules_validation(self, data: Any, format_type: str) -> Tuple[List[str], List[str]]:
        """–ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –±—ñ–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª"""
        errors = []
        warnings = []
        
        try:
            if format_type == "spdx":
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –æ–±–æ–≤'—è–∑–∫–æ–≤–∏—Ö –ø–æ–ª—ñ–≤
                if not data.get("name"):
                    errors.append("–í—ñ–¥—Å—É—Ç–Ω—è –Ω–∞–∑–≤–∞ –¥–æ–∫—É–º–µ–Ω—Ç–∞")
                
                if not data.get("packages"):
                    warnings.append("–î–æ–∫—É–º–µ–Ω—Ç –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –ø–∞–∫–µ—Ç—ñ–≤")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –ª—ñ—Ü–µ–Ω–∑—ñ–π
                packages = data.get("packages", [])
                unlicensed_packages = [p.get("name", "unknown") for p in packages 
                                     if not p.get("licenseConcluded")]
                if unlicensed_packages:
                    warnings.append(f"–ü–∞–∫–µ—Ç–∏ –±–µ–∑ –ª—ñ—Ü–µ–Ω–∑—ñ–π: {', '.join(unlicensed_packages[:3])}")
            
            elif format_type == "cyclonedx":
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –º–µ—Ç–∞–¥–∞–Ω–∏—Ö
                metadata = data.get("metadata", {})
                if not metadata.get("timestamp"):
                    warnings.append("–í—ñ–¥—Å—É—Ç–Ω—è –º—ñ—Ç–∫–∞ —á–∞—Å—É")
                
                if not metadata.get("authors"):
                    warnings.append("–í—ñ–¥—Å—É—Ç–Ω—è —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –∞–≤—Ç–æ—Ä—ñ–≤")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
                components = data.get("components", [])
                if not components:
                    errors.append("SBOM –Ω–µ –º—ñ—Å—Ç–∏—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤")
                
                # –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤–µ—Ä—Å—ñ–π –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
                unversioned_components = [c.get("name", "unknown") for c in components 
                                        if not c.get("version")]
                if unversioned_components:
                    warnings.append(f"–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ –±–µ–∑ –≤–µ—Ä—Å—ñ–π: {', '.join(unversioned_components[:3])}")
        
        except Exception as e:
            errors.append(f"–ü–æ–º–∏–ª–∫–∞ –±—ñ–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª: {str(e)}")
        
        return errors, warnings
    
    def semantic_analysis(self, data: Any, format_type: str) -> Dict[str, Any]:
        """–°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ SBOM"""
        analysis = {
            "component_stats": {},
            "dependency_analysis": {},
            "license_analysis": {},
            "security_analysis": {},
            "quality_metrics": {}
        }
        
        try:
            if format_type == "spdx":
                packages = data.get("packages", [])
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
                analysis["component_stats"] = {
                    "total_packages": len(packages),
                    "with_versions": len([p for p in packages if p.get("versionInfo")]),
                    "with_licenses": len([p for p in packages if p.get("licenseConcluded")]),
                    "package_types": {}
                }
                
                # –ê–Ω–∞–ª—ñ–∑ –ª—ñ—Ü–µ–Ω–∑—ñ–π
                licenses = [p.get("licenseConcluded", "Unknown") for p in packages]
                license_counts = pd.Series(licenses).value_counts().to_dict()
                analysis["license_analysis"] = {
                    "distribution": license_counts,
                    "unique_licenses": len(set(licenses)),
                    "unlicensed_count": licenses.count("NOASSERTION") + licenses.count("Unknown")
                }
            
            elif format_type == "cyclonedx":
                components = data.get("components", [])
                
                # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
                component_types = [c.get("type", "unknown") for c in components]
                analysis["component_stats"] = {
                    "total_components": len(components),
                    "with_versions": len([c for c in components if c.get("version")]),
                    "with_licenses": len([c for c in components if c.get("licenses")]),
                    "component_types": pd.Series(component_types).value_counts().to_dict()
                }
                
                # –ê–Ω–∞–ª—ñ–∑ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π
                dependencies = data.get("dependencies", [])
                analysis["dependency_analysis"] = {
                    "total_dependencies": len(dependencies),
                    "dependency_graph_depth": self._calculate_dependency_depth(dependencies),
                    "root_components": self._find_root_components(dependencies),
                    "leaf_components": self._find_leaf_components(dependencies)
                }
                
                # –ê–Ω–∞–ª—ñ–∑ –ª—ñ—Ü–µ–Ω–∑—ñ–π
                all_licenses = []
                for component in components:
                    licenses = component.get("licenses", [])
                    for license_info in licenses:
                        if isinstance(license_info, dict):
                            license_id = license_info.get("license", {}).get("id", "Unknown")
                            all_licenses.append(license_id)
                
                license_counts = pd.Series(all_licenses).value_counts().to_dict()
                analysis["license_analysis"] = {
                    "distribution": license_counts,
                    "unique_licenses": len(set(all_licenses)),
                    "unlicensed_count": all_licenses.count("Unknown")
                }
                
                # –ê–Ω–∞–ª—ñ–∑ –±–µ–∑–ø–µ–∫–∏ (—è–∫—â–æ —î –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç—ñ)
                vulnerabilities = []
                for component in components:
                    if "vulnerabilities" in component:
                        vulnerabilities.extend(component["vulnerabilities"])
                
                if vulnerabilities:
                    severity_counts = {}
                    for vuln in vulnerabilities:
                        severity = vuln.get("severity", "unknown")
                        severity_counts[severity] = severity_counts.get(severity, 0) + 1
                    
                    analysis["security_analysis"] = {
                        "total_vulnerabilities": len(vulnerabilities),
                        "severity_distribution": severity_counts,
                        "critical_count": severity_counts.get("critical", 0),
                        "high_count": severity_counts.get("high", 0)
                    }
        
        except Exception as e:
            analysis["error"] = f"–ü–æ–º–∏–ª–∫–∞ –∞–Ω–∞–ª—ñ–∑—É: {str(e)}"
        
        return analysis
    
    def _calculate_dependency_depth(self, dependencies: List[Dict]) -> int:
        """–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –≥–ª–∏–±–∏–Ω–∏ –≥—Ä–∞—Ñ–∞ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π"""
        if not dependencies:
            return 0
        
        try:
            G = nx.DiGraph()
            for dep in dependencies:
                ref = dep.get("ref", "")
                depends_on = dep.get("dependsOn", [])
                for target in depends_on:
                    G.add_edge(ref, target)
            
            if G.nodes():
                try:
                    return max(nx.shortest_path_length(G, source).values() 
                             for source in G.nodes() if G.out_degree(source) > 0)
                except:
                    return len(G.nodes())
            return 0
        except:
            return 0
    
    def _find_root_components(self, dependencies: List[Dict]) -> List[str]:
        """–ü–æ—à—É–∫ –∫–æ—Ä–µ–Ω–µ–≤–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤"""
        all_refs = set()
        dependent_refs = set()
        
        for dep in dependencies:
            ref = dep.get("ref", "")
            all_refs.add(ref)
            dependent_refs.update(dep.get("dependsOn", []))
        
        return list(all_refs - dependent_refs)
    
    def _find_leaf_components(self, dependencies: List[Dict]) -> List[str]:
        """–ü–æ—à—É–∫ –ª–∏—Å—Ç–æ–≤–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤"""
        return [dep.get("ref", "") for dep in dependencies 
                if not dep.get("dependsOn")]
    
    def calculate_quality_score(self, data: Any, format_type: str, errors: List[str], 
                              warnings: List[str], analysis: Dict[str, Any]) -> int:
        """–†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –æ—Ü—ñ–Ω–∫–∏ —è–∫–æ—Å—Ç—ñ (0-100)"""
        score = 100
        
        # –®—Ç—Ä–∞—Ñ–∏ –∑–∞ –ø–æ–º–∏–ª–∫–∏
        score -= len(errors) * 20
        score -= len(warnings) * 5
        
        try:
            if format_type == "cyclonedx":
                # –°—Ç—Ä—É–∫—Ç—É—Ä–∞ (20%)
                if "bomFormat" not in data or "specVersion" not in data:
                    score -= 20
                
                # –ú–µ—Ç–∞–¥–∞–Ω—ñ (20%)
                metadata = data.get("metadata", {})
                metadata_score = 0
                if metadata.get("timestamp"):
                    metadata_score += 5
                if metadata.get("authors"):
                    metadata_score += 5
                if metadata.get("tools"):
                    metadata_score += 5
                if metadata.get("component"):
                    metadata_score += 5
                score += metadata_score - 20
                
                # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏ (40%)
                components = data.get("components", [])
                if components:
                    with_versions = len([c for c in components if c.get("version")])
                    with_licenses = len([c for c in components if c.get("licenses")])
                    
                    version_ratio = with_versions / len(components)
                    license_ratio = with_licenses / len(components)
                    
                    component_score = (version_ratio * 20) + (license_ratio * 20)
                    score += component_score - 40
                else:
                    score -= 40
                
                # –ë–µ–∑–ø–µ–∫–∞ (20%)
                security_score = 0
                if analysis.get("security_analysis"):
                    # –Ø–∫—â–æ —î –∞–Ω–∞–ª—ñ–∑ –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç–µ–π, —Ü–µ –¥–æ–±—Ä–µ
                    security_score += 10
                    sec_analysis = analysis["security_analysis"]
                    if sec_analysis.get("critical_count", 0) == 0:
                        security_score += 5
                    if sec_analysis.get("high_count", 0) == 0:
                        security_score += 5
                else:
                    # –í—ñ–¥—Å—É—Ç–Ω—ñ—Å—Ç—å —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –±–µ–∑–ø–µ–∫—É
                    security_score += 10
                
                score += security_score - 20
            
            elif format_type == "spdx":
                # –°–ø—Ä–æ—â–µ–Ω–∏–π —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –¥–ª—è SPDX
                packages = data.get("packages", [])
                if packages:
                    with_licenses = len([p for p in packages if p.get("licenseConcluded")])
                    license_ratio = with_licenses / len(packages)
                    score += (license_ratio * 40) - 40
                else:
                    score -= 30
        
        except Exception:
            score -= 10
        
        return max(0, min(100, int(score)))
    
    def validate(self, content: str, filename: str = "", 
                validation_level: str = "standard") -> ValidationResult:
        """–ì–æ–ª–æ–≤–Ω–∞ —Ñ—É–Ω–∫—Ü—ñ—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó"""
        start_time = time.time()
        
        # Auto-detection
        format_type, version, data_type = self.detect_sbom_format(content, filename)
        
        errors = []
        warnings = []
        analysis = {}
        
        if format_type == "unknown":
            return ValidationResult(
                is_valid=False,
                format_type=format_type,
                version=version,
                data_type=data_type,
                errors=["–ù–µ –≤–¥–∞–ª–æ—Å—è –≤–∏–∑–Ω–∞—á–∏—Ç–∏ —Ñ–æ—Ä–º–∞—Ç SBOM"],
                warnings=[],
                quality_score=0,
                analysis={},
                processing_time=time.time() - start_time
            )
        
        try:
            # –ü–∞—Ä—Å–∏–Ω–≥ –¥–∞–Ω–∏—Ö
            if data_type == "json":
                data = json.loads(content)
            elif data_type == "xml":
                data = ET.fromstring(content)
            else:
                raise ValueError(f"–ù–µ–ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏–π —Ç–∏–ø –¥–∞–Ω–∏—Ö: {data_type}")
            
            # –ë–∞–∑–æ–≤–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è —Å—Ö–µ–º–∏
            is_valid_schema, schema_errors = self.validate_schema(data, format_type, version, data_type)
            errors.extend(schema_errors)
            
            # –†–æ–∑—à–∏—Ä–µ–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è
            if validation_level in ["standard", "comprehensive"]:
                business_errors, business_warnings = self.business_rules_validation(data, format_type)
                errors.extend(business_errors)
                warnings.extend(business_warnings)
            
            # –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
            if validation_level == "comprehensive":
                analysis = self.semantic_analysis(data, format_type)
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –æ—Ü—ñ–Ω–∫–∏ —è–∫–æ—Å—Ç—ñ
            quality_score = self.calculate_quality_score(data, format_type, errors, warnings, analysis)
            
            is_valid = len(errors) == 0
        
        except json.JSONDecodeError as e:
            errors.append(f"–ü–æ–º–∏–ª–∫–∞ JSON: {str(e)}")
            is_valid = False
            quality_score = 0
        
        except ET.ParseError as e:
            errors.append(f"–ü–æ–º–∏–ª–∫–∞ XML: {str(e)}")
            is_valid = False
            quality_score = 0
        
        except Exception as e:
            errors.append(f"–ó–∞–≥–∞–ª—å–Ω–∞ –ø–æ–º–∏–ª–∫–∞: {str(e)}")
            is_valid = False
            quality_score = 0
        
        processing_time = time.time() - start_time
        
        return ValidationResult(
            is_valid=is_valid,
            format_type=format_type,
            version=version,
            data_type=data_type,
            errors=errors,
            warnings=warnings,
            quality_score=quality_score,
            analysis=analysis,
            processing_time=processing_time
        )

def create_quality_gauge(score: int) -> go.Figure:
    """–°—Ç–≤–æ—Ä–µ–Ω–Ω—è gauge –¥–ª—è –æ—Ü—ñ–Ω–∫–∏ —è–∫–æ—Å—Ç—ñ"""
    if score >= 80:
        color = "green"
        category = "–í—ñ–¥–º—ñ–Ω–Ω–∞"
    elif score >= 60:
        color = "blue"
        category = "–•–æ—Ä–æ—à–∞"
    elif score >= 40:
        color = "yellow"
        category = "–ó–∞–¥–æ–≤—ñ–ª—å–Ω–∞"
    else:
        color = "red"
        category = "–ü–æ–≥–∞–Ω–∞"
    
    fig = go.Figure(go.Indicator(
        mode = "gauge+number+delta",
        value = score,
        domain = {'x': [0, 1], 'y': [0, 1]},
        title = {'text': f"–Ø–∫—ñ—Å—Ç—å SBOM<br><span style='font-size:0.8em;color:gray'>{category}</span>"},
        delta = {'reference': 50},
        gauge = {
            'axis': {'range': [None, 100]},
            'bar': {'color': color},
            'steps': [
                {'range': [0, 40], 'color': "lightgray"},
                {'range': [40, 60], 'color': "gray"},
                {'range': [60, 80], 'color': "lightblue"},
                {'range': [80, 100], 'color': "lightgreen"}
            ],
            'threshold': {
                'line': {'color': "red", 'width': 4},
                'thickness': 0.75,
                'value': 90
            }
        }
    ))
    
    fig.update_layout(height=400, font={'color': "darkblue", 'family': "Arial"})
    return fig

def main():
    # –ó–∞–≥–æ–ª–æ–≤–æ–∫
    st.markdown("""
    <div class="main-header">
        <h1>üõ°Ô∏è SBOM Validator</h1>
        <p>–£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –≤–∞–ª—ñ–¥–∞—Ç–æ—Ä –¥–ª—è SPDX 2.3/3.0 —Ç–∞ CycloneDX 1.3-1.6 –∑ –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–∏–º –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è–º —Ñ–æ—Ä–º–∞—Ç—É</p>
    </div>
    """, unsafe_allow_html=True)
    
    # Sidebar –Ω–∞–≤—ñ–≥–∞—Ü—ñ—è
    st.sidebar.title("üß≠ –ù–∞–≤—ñ–≥–∞—Ü—ñ—è")
    page = st.sidebar.selectbox(
        "–í–∏–±–µ—Ä—ñ—Ç—å —Ä–æ–∑–¥—ñ–ª:",
        ["üè† –ì–æ–ª–æ–≤–Ω–∞", "‚úÖ –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –≤–∞–ª—ñ–¥–∞—Ç–æ—Ä", "üìä –ü–∞–∫–µ—Ç–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è", 
         "üìã –ë—Ä–∞—É–∑–µ—Ä —Å—Ö–µ–º", "üìù –ü—Ä–∏–∫–ª–∞–¥–∏ —Ç–∞ —Ç–µ—Å—Ç–∏", "üîç –†–æ–∑—à–∏—Ä–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑", 
         "üìà –ú–∞—Ç—Ä–∏—Ü—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏"]
    )
    
    validator = EnhancedSBOMValidator()
    
    if page == "üè† –ì–æ–ª–æ–≤–Ω–∞":
        show_home_page(validator)
    elif page == "‚úÖ –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –≤–∞–ª—ñ–¥–∞—Ç–æ—Ä":
        show_universal_validator(validator)
    elif page == "üìä –ü–∞–∫–µ—Ç–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è":
        show_batch_validator(validator)
    elif page == "üìã –ë—Ä–∞—É–∑–µ—Ä —Å—Ö–µ–º":
        show_schema_browser(validator)
    elif page == "üìù –ü—Ä–∏–∫–ª–∞–¥–∏ —Ç–∞ —Ç–µ—Å—Ç–∏":
        show_examples_page(validator)
    elif page == "üîç –†–æ–∑—à–∏—Ä–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑":
        show_advanced_analysis(validator)
    elif page == "üìà –ú–∞—Ç—Ä–∏—Ü—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏":
        show_support_matrix(validator)

def show_home_page(validator):
    st.header("üöÄ –û–≥–ª—è–¥ –º–æ–∂–ª–∏–≤–æ—Å—Ç–µ–π")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.markdown("""
        <div class="metric-card">
            <h3>üéØ Auto-Detection</h3>
            <p>–ê–≤—Ç–æ–º–∞—Ç–∏—á–Ω–µ –≤–∏–∑–Ω–∞—á–µ–Ω–Ω—è —Ñ–æ—Ä–º–∞—Ç—É, –≤–µ—Ä—Å—ñ—ó —Ç–∞ —Ç–∏–ø—É –¥–∞–Ω–∏—Ö SBOM</p>
            <ul>
                <li>SPDX 2.3/3.0 (JSON)</li>
                <li>CycloneDX 1.3-1.6 (JSON/XML)</li>
                <li>–Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col2:
        st.markdown("""
        <div class="metric-card">
            <h3>üîç –¢—Ä–∏—Ä—ñ–≤–Ω–µ–≤–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è</h3>
            <p>–í–∏–±—ñ—Ä —Ä—ñ–≤–Ω—è –¥–µ—Ç–∞–ª—ñ–∑–∞—Ü—ñ—ó –ø–µ—Ä–µ–≤—ñ—Ä–∫–∏</p>
            <ul>
                <li><b>Basic:</b> –°–∏–Ω—Ç–∞–∫—Å–∏—Å + —Å—Ö–µ–º–∞</li>
                <li><b>Standard:</b> + –±—ñ–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞</li>
                <li><b>Comprehensive:</b> + —Å–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    with col3:
        st.markdown("""
        <div class="metric-card">
            <h3>üìä –†–æ–∑—à–∏—Ä–µ–Ω–∞ –∞–Ω–∞–ª—ñ—Ç–∏–∫–∞</h3>
            <p>–ì–ª–∏–±–æ–∫–∏–π –∞–Ω–∞–ª—ñ–∑ SBOM –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤</p>
            <ul>
                <li>–û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ (0-100)</li>
                <li>–ê–Ω–∞–ª—ñ–∑ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π</li>
                <li>–†–æ–∑–ø–æ–¥—ñ–ª –ª—ñ—Ü–µ–Ω–∑—ñ–π</li>
                <li>–ê–Ω–∞–ª—ñ–∑ –±–µ–∑–ø–µ–∫–∏</li>
            </ul>
        </div>
        """, unsafe_allow_html=True)
    
    st.header("üåü –£–Ω—ñ–∫–∞–ª—å–Ω—ñ –æ—Å–æ–±–ª–∏–≤–æ—Å—Ç—ñ")
    
    features_col1, features_col2 = st.columns(2)
    
    with features_col1:
        st.subheader("üß† –Ü–Ω—Ç–µ–ª–µ–∫—Ç—É–∞–ª—å–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ")
        st.markdown("""
        - **Smart Auto-Detection**: –†–æ–∑–ø—ñ–∑–Ω–∞–≤–∞–Ω–Ω—è —Ñ–æ—Ä–º–∞—Ç—É –∑–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é —Ç–∞ –º–µ—Ç–∞–¥–∞–Ω–∏–º–∏
        - **Quality Scoring**: –ê–ª–≥–æ—Ä–∏—Ç–º –æ—Ü—ñ–Ω–∫–∏ —è–∫–æ—Å—Ç—ñ –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–æ–≤–Ω–æ—Ç–∏ —Ç–∞ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—ñ
        - **Semantic Analysis**: –ì–ª–∏–±–æ–∫–∏–π –∞–Ω–∞–ª—ñ–∑ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤, –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π —Ç–∞ –ª—ñ—Ü–µ–Ω–∑—ñ–π
        - **Business Rules**: –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–Ω–æ—Å—Ç—ñ –∫—Ä–∞—â–∏–º –ø—Ä–∞–∫—Ç–∏–∫–∞–º
        """)
    
    with features_col2:
        st.subheader("‚ö° –ü—Ä–æ—Ñ–µ—Å—ñ–π–Ω—ñ —Ñ—É–Ω–∫—Ü—ñ—ó")
        st.markdown("""
        - **Batch Processing**: –í–∞–ª—ñ–¥–∞—Ü—ñ—è –º–Ω–æ–∂–∏–Ω–∏ —Ñ–∞–π–ª—ñ–≤ –æ–¥–Ω–æ—á–∞—Å–Ω–æ
        - **Export Results**: JSON –∑–≤—ñ—Ç–∏ –¥–ª—è —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—ó –≤ CI/CD
        - **Performance Metrics**: –ú–æ–Ω—ñ—Ç–æ—Ä–∏–Ω–≥ —á–∞—Å—É –æ–±—Ä–æ–±–∫–∏
        - **Interactive Visualizations**: –ì—Ä–∞—Ñ—ñ–∫–∏ —Ç–∞ –¥—ñ–∞–≥—Ä–∞–º–∏ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
        """)

def show_universal_validator(validator):
    st.header("‚úÖ –£–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π SBOM –≤–∞–ª—ñ–¥–∞—Ç–æ—Ä")
    
    # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("üìÅ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—É")
        uploaded_file = st.file_uploader(
            "–í–∏–±–µ—Ä—ñ—Ç—å SBOM —Ñ–∞–π–ª",
            type=['json', 'xml'],
            help="–ü—ñ–¥—Ç—Ä–∏–º—É—é—Ç—å—Å—è SPDX (JSON) —Ç–∞ CycloneDX (JSON/XML) —Ñ–∞–π–ª–∏"
        )
    
    with col2:
        st.subheader("‚öôÔ∏è –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è")
        validation_level = st.selectbox(
            "–†—ñ–≤–µ–Ω—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó:",
            ["basic", "standard", "comprehensive"],
            index=1,
            format_func=lambda x: {
                "basic": "üî∏ Basic - —Å–∏–Ω—Ç–∞–∫—Å–∏—Å + —Å—Ö–µ–º–∞",
                "standard": "üî∂ Standard + –±—ñ–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞",
                "comprehensive": "üî∫ Comprehensive + —Å–µ–º–∞–Ω—Ç–∏–∫–∞"
            }[x]
        )
        
        auto_detect = st.checkbox("üéØ Auto-detection", value=True)
        show_raw_content = st.checkbox("üìù –ü–æ–∫–∞–∑–∞—Ç–∏ –≤–º—ñ—Å—Ç —Ñ–∞–π–ª—É", value=False)
    
    # –¢–µ–∫—Å—Ç–æ–≤–µ –ø–æ–ª–µ –¥–ª—è –ø—Ä—è–º–æ–≥–æ –≤–≤–µ–¥–µ–Ω–Ω—è
    st.subheader("‚úèÔ∏è –ê–±–æ –≤–≤–µ–¥—ñ—Ç—å SBOM –±–µ–∑–ø–æ—Å–µ—Ä–µ–¥–Ω—å–æ:")
    manual_input = st.text_area(
        "SBOM –∫–æ–Ω—Ç–µ–Ω—Ç:",
        height=200,
        placeholder='{"bomFormat": "CycloneDX", "specVersion": "1.4", ...}'
    )
    
    # –í–∞–ª—ñ–¥–∞—Ü—ñ—è
    if st.button("üöÄ –í–∞–ª—ñ–¥—É–≤–∞—Ç–∏ SBOM", type="primary"):
        content = None
        filename = ""
        
        if uploaded_file is not None:
            content = uploaded_file.read().decode('utf-8')
            filename = uploaded_file.name
        elif manual_input.strip():
            content = manual_input.strip()
            filename = "manual_input"
        
        if content:
            with st.spinner('–í–∏–∫–æ–Ω—É—î—Ç—å—Å—è –≤–∞–ª—ñ–¥–∞—Ü—ñ—è...'):
                result = validator.validate(content, filename, validation_level)
            
            # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
            display_validation_results(result, show_raw_content, content)
        else:
            st.warning("‚ö†Ô∏è –ë—É–¥—å –ª–∞—Å–∫–∞, –∑–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ —Ñ–∞–π–ª –∞–±–æ –≤–≤–µ–¥—ñ—Ç—å SBOM –∫–æ–Ω—Ç–µ–Ω—Ç")

def display_validation_results(result: ValidationResult, show_raw_content: bool, content: str):
    """–í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó"""
    
    # –ó–∞–≥–∞–ª—å–Ω–∏–π —Å—Ç–∞—Ç—É—Å
    if result.is_valid:
        st.success("‚úÖ SBOM –≤–∞–ª—ñ–¥–Ω–∏–π!")
    else:
        st.error("‚ùå SBOM –º—ñ—Å—Ç–∏—Ç—å –ø–æ–º–∏–ª–∫–∏")
    
    # –ú–µ—Ç—Ä–∏–∫–∏
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric("üìã –§–æ—Ä–º–∞—Ç", f"{result.format_type.upper()}")
    
    with col2:
        st.metric("üî¢ –í–µ—Ä—Å—ñ—è", result.version)
    
    with col3:
        st.metric("üìÅ –¢–∏–ø", result.data_type.upper())
    
    with col4:
        st.metric("‚è±Ô∏è –ß–∞—Å –æ–±—Ä–æ–±–∫–∏", f"{result.processing_time:.2f}—Å")
    
    # –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ
    st.subheader("üìä –û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ SBOM")
    col1, col2 = st.columns([1, 2])
    
    with col1:
        # Gauge –¥—ñ–∞–≥—Ä–∞–º–∞
        quality_fig = create_quality_gauge(result.quality_score)
        st.plotly_chart(quality_fig, use_container_width=True)
    
    with col2:
        # –î–µ—Ç–∞–ª—å–Ω–∞ –æ—Ü—ñ–Ω–∫–∞
        quality_class = ""
        if result.quality_score >= 80:
            quality_class = "quality-excellent"
            quality_text = "–í—ñ–¥–º—ñ–Ω–Ω–∞ —è–∫—ñ—Å—Ç—å"
        elif result.quality_score >= 60:
            quality_class = "quality-good"
            quality_text = "–•–æ—Ä–æ—à–∞ —è–∫—ñ—Å—Ç—å"
        elif result.quality_score >= 40:
            quality_class = "quality-warning"
            quality_text = "–ó–∞–¥–æ–≤—ñ–ª—å–Ω–∞ —è–∫—ñ—Å—Ç—å"
        else:
            quality_class = "quality-poor"
            quality_text = "–ü–æ—Ç—Ä–µ–±—É—î –ø–æ–∫—Ä–∞—â–µ–Ω–Ω—è"
        
        st.markdown(f"""
        <div class="metric-card">
            <div class="quality-score {quality_class}">{result.quality_score}/100</div>
            <h4>{quality_text}</h4>
            <p>–û—Ü—ñ–Ω–∫–∞ –±–∞–∑—É—î—Ç—å—Å—è –Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä—ñ, –º–µ—Ç–∞–¥–∞–Ω–∏—Ö, –ø–æ–≤–Ω–æ—Ç—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤ —Ç–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –±–µ–∑–ø–µ–∫—É</p>
        </div>
        """, unsafe_allow_html=True)
    
    # –ü–æ–º–∏–ª–∫–∏ —Ç–∞ –ø–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è
    if result.errors:
        st.subheader("‚ùå –ü–æ–º–∏–ª–∫–∏")
        for error in result.errors:
            st.markdown(f"""
            <div class="error-box">
                <strong>–ü–æ–º–∏–ª–∫–∞:</strong> {error}
            </div>
            """, unsafe_allow_html=True)
    
    if result.warnings:
        st.subheader("‚ö†Ô∏è –ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è")
        for warning in result.warnings:
            st.markdown(f"""
            <div class="warning-box">
                <strong>–ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è:</strong> {warning}
            </div>
            """, unsafe_allow_html=True)
    
    # –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑
    if result.analysis:
        st.subheader("üß† –°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑")
        display_semantic_analysis(result.analysis)
    
    # –ï–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    st.subheader("üì§ –ï–∫—Å–ø–æ—Ä—Ç —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
    export_data = {
        "timestamp": datetime.now().isoformat(),
        "validation_result": {
            "is_valid": result.is_valid,
            "format_type": result.format_type,
            "version": result.version,
            "data_type": result.data_type,
            "quality_score": result.quality_score,
            "processing_time": result.processing_time,
            "errors": result.errors,
            "warnings": result.warnings,
            "analysis": result.analysis
        }
    }
    
    export_json = json.dumps(export_data, indent=2, ensure_ascii=False)
    st.download_button(
        "üíæ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ JSON –∑–≤—ñ—Ç",
        export_json,
        file_name=f"sbom_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json"
    )
    
    # –ü–æ–∫–∞–∑–∞—Ç–∏ –≤–º—ñ—Å—Ç —Ñ–∞–π–ª—É
    if show_raw_content:
        st.subheader("üìù –í–º—ñ—Å—Ç —Ñ–∞–π–ª—É")
        st.code(content, language="json" if result.data_type == "json" else "xml")

def display_semantic_analysis(analysis: Dict[str, Any]):
    """–í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Å–µ–º–∞–Ω—Ç–∏—á–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É"""
    
    tabs = st.tabs(["üìä –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏", "üîó –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ", "‚öñÔ∏è –õ—ñ—Ü–µ–Ω–∑—ñ—ó", "üõ°Ô∏è –ë–µ–∑–ø–µ–∫–∞"])
    
    with tabs[0]:  # –ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏
        if "component_stats" in analysis:
            stats = analysis["component_stats"]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üì¶ –í—Å—å–æ–≥–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤", stats.get("total_components", stats.get("total_packages", 0)))
            with col2:
                st.metric("üî¢ –ó –≤–µ—Ä—Å—ñ—è–º–∏", stats.get("with_versions", 0))
            with col3:
                st.metric("‚öñÔ∏è –ó –ª—ñ—Ü–µ–Ω–∑—ñ—è–º–∏", stats.get("with_licenses", 0))
            
            # –î—ñ–∞–≥—Ä–∞–º–∞ —Ç–∏–ø—ñ–≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
            if "component_types" in stats and stats["component_types"]:
                types_df = pd.DataFrame(list(stats["component_types"].items()), 
                                      columns=["–¢–∏–ø", "–ö—ñ–ª—å–∫—ñ—Å—Ç—å"])
                fig = px.pie(types_df, values="–ö—ñ–ª—å–∫—ñ—Å—Ç—å", names="–¢–∏–ø", 
                           title="–†–æ–∑–ø–æ–¥—ñ–ª —Ç–∏–ø—ñ–≤ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤")
                st.plotly_chart(fig, use_container_width=True)
    
    with tabs[1]:  # –ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ
        if "dependency_analysis" in analysis:
            deps = analysis["dependency_analysis"]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üîó –í—Å—å–æ–≥–æ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π", deps.get("total_dependencies", 0))
            with col2:
                st.metric("üìè –ì–ª–∏–±–∏–Ω–∞ –≥—Ä–∞—Ñ–∞", deps.get("dependency_graph_depth", 0))
            with col3:
                st.metric("üå≥ –ö–æ—Ä–µ–Ω–µ–≤–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤", len(deps.get("root_components", [])))
            
            # –°–ø–∏—Å–æ–∫ –∫–æ—Ä–µ–Ω–µ–≤–∏—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤
            if deps.get("root_components"):
                st.write("**–ö–æ—Ä–µ–Ω–µ–≤—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏:**")
                for root in deps["root_components"][:10]:  # –ü–æ–∫–∞–∑—É—î–º–æ –ø–µ—Ä—à—ñ 10
                    st.write(f"- {root}")
    
    with tabs[2]:  # –õ—ñ—Ü–µ–Ω–∑—ñ—ó
        if "license_analysis" in analysis:
            licenses = analysis["license_analysis"]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("‚öñÔ∏è –£–Ω—ñ–∫–∞–ª—å–Ω–∏—Ö –ª—ñ—Ü–µ–Ω–∑—ñ–π", licenses.get("unique_licenses", 0))
            with col2:
                st.metric("‚ùì –ë–µ–∑ –ª—ñ—Ü–µ–Ω–∑—ñ–π", licenses.get("unlicensed_count", 0))
            with col3:
                total_licenses = sum(licenses.get("distribution", {}).values())
                st.metric("üìä –í—Å—å–æ–≥–æ –∑–∞–ø–∏—Å—ñ–≤", total_licenses)
            
            # –î—ñ–∞–≥—Ä–∞–º–∞ —Ä–æ–∑–ø–æ–¥—ñ–ª—É –ª—ñ—Ü–µ–Ω–∑—ñ–π
            if "distribution" in licenses and licenses["distribution"]:
                license_df = pd.DataFrame(list(licenses["distribution"].items()), 
                                        columns=["–õ—ñ—Ü–µ–Ω–∑—ñ—è", "–ö—ñ–ª—å–∫—ñ—Å—Ç—å"])
                license_df = license_df.sort_values("–ö—ñ–ª—å–∫—ñ—Å—Ç—å", ascending=False).head(10)
                
                fig = px.bar(license_df, x="–õ—ñ—Ü–µ–Ω–∑—ñ—è", y="–ö—ñ–ª—å–∫—ñ—Å—Ç—å", 
                           title="–¢–æ–ø-10 –ª—ñ—Ü–µ–Ω–∑—ñ–π")
                fig.update_xaxes(tickangle=45)
                st.plotly_chart(fig, use_container_width=True)
    
    with tabs[3]:  # –ë–µ–∑–ø–µ–∫–∞
        if "security_analysis" in analysis:
            security = analysis["security_analysis"]
            
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("üö® –í—Å—å–æ–≥–æ –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç–µ–π", security.get("total_vulnerabilities", 0))
            with col2:
                st.metric("üíÄ –ö—Ä–∏—Ç–∏—á–Ω–∏—Ö", security.get("critical_count", 0))
            with col3:
                st.metric("üî¥ –í–∏—Å–æ–∫–æ–≥–æ —Ä—ñ–≤–Ω—è", security.get("high_count", 0))
            
            # –î—ñ–∞–≥—Ä–∞–º–∞ —Ä–æ–∑–ø–æ–¥—ñ–ª—É –∑–∞ —Ä—ñ–≤–Ω—è–º–∏ —Å–µ—Ä–π–æ–∑–Ω–æ—Å—Ç—ñ
            if "severity_distribution" in security and security["severity_distribution"]:
                sev_df = pd.DataFrame(list(security["severity_distribution"].items()), 
                                    columns=["–†—ñ–≤–µ–Ω—å", "–ö—ñ–ª—å–∫—ñ—Å—Ç—å"])
                
                color_map = {
                    "critical": "#8B0000",
                    "high": "#DC143C", 
                    "medium": "#FF8C00",
                    "low": "#32CD32",
                    "unknown": "#808080"
                }
                
                fig = px.bar(sev_df, x="–†—ñ–≤–µ–Ω—å", y="–ö—ñ–ª—å–∫—ñ—Å—Ç—å",
                           title="–†–æ–∑–ø–æ–¥—ñ–ª –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç–µ–π –∑–∞ —Ä—ñ–≤–Ω–µ–º —Å–µ—Ä–π–æ–∑–Ω–æ—Å—Ç—ñ",
                           color="–†—ñ–≤–µ–Ω—å", color_discrete_map=color_map)
                st.plotly_chart(fig, use_container_width=True)
        else:
            st.info("‚ÑπÔ∏è –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç—ñ –≤—ñ–¥—Å—É—Ç–Ω—è –≤ SBOM")

def show_batch_validator(validator):
    st.header("üìä –ü–∞–∫–µ—Ç–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è SBOM")
    
    st.markdown("""
    –ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ –¥–µ–∫—ñ–ª—å–∫–∞ SBOM —Ñ–∞–π–ª—ñ–≤ –¥–ª—è –æ–¥–Ω–æ—á–∞—Å–Ω–æ—ó –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó —Ç–∞ –ø–æ—Ä—ñ–≤–Ω—è–ª—å–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É.
    """)
    
    # –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤
    uploaded_files = st.file_uploader(
        "–í–∏–±–µ—Ä—ñ—Ç—å SBOM —Ñ–∞–π–ª–∏",
        type=['json', 'xml'],
        accept_multiple_files=True,
        help="–ú–æ–∂–Ω–∞ –∑–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –¥–æ 10 —Ñ–∞–π–ª—ñ–≤ –æ–¥–Ω–æ—á–∞—Å–Ω–æ"
    )
    
    validation_level = st.selectbox(
        "–†—ñ–≤–µ–Ω—å –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó:",
        ["basic", "standard", "comprehensive"],
        index=1,
        key="batch_validation_level"
    )
    
    if uploaded_files and st.button("üöÄ –í–∞–ª—ñ–¥—É–≤–∞—Ç–∏ –≤—Å—ñ —Ñ–∞–π–ª–∏", type="primary"):
        if len(uploaded_files) > 10:
            st.error("‚ùå –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –∫—ñ–ª—å–∫—ñ—Å—Ç—å —Ñ–∞–π–ª—ñ–≤ - 10")
            return
        
        results = []
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        for i, file in enumerate(uploaded_files):
            status_text.text(f"–û–±—Ä–æ–±–∫–∞ {file.name}...")
            content = file.read().decode('utf-8')
            result = validator.validate(content, file.name, validation_level)
            results.append((file.name, result))
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        status_text.text("–ì–æ—Ç–æ–≤–æ!")
        
        # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
        display_batch_results(results)

def display_batch_results(results: List[Tuple[str, ValidationResult]]):
    """–í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –ø–∞–∫–µ—Ç–Ω–æ—ó –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó"""
    
    # –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
    st.subheader("üìà –ó–∞–≥–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞")
    
    total_files = len(results)
    valid_files = sum(1 for _, result in results if result.is_valid)
    avg_quality = sum(result.quality_score for _, result in results) / total_files
    
    col1, col2, col3, col4 = st.columns(4)
    with col1:
        st.metric("üìÅ –í—Å—å–æ–≥–æ —Ñ–∞–π–ª—ñ–≤", total_files)
    with col2:
        st.metric("‚úÖ –í–∞–ª—ñ–¥–Ω–∏—Ö", valid_files)
    with col3:
        st.metric("‚ùå –ó –ø–æ–º–∏–ª–∫–∞–º–∏", total_files - valid_files)
    with col4:
        st.metric("üìä –°–µ—Ä–µ–¥–Ω—è —è–∫—ñ—Å—Ç—å", f"{avg_quality:.1f}")
    
    # –¢–∞–±–ª–∏—Ü—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤
    st.subheader("üìã –î–µ—Ç–∞–ª—ñ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó")
    
    table_data = []
    for filename, result in results:
        status = "‚úÖ –í–∞–ª—ñ–¥–Ω–∏–π" if result.is_valid else "‚ùå –ü–æ–º–∏–ª–∫–∏"
        table_data.append({
            "–§–∞–π–ª": filename,
            "–°—Ç–∞—Ç—É—Å": status,
            "–§–æ—Ä–º–∞—Ç": f"{result.format_type.upper()} {result.version}",
            "–¢–∏–ø": result.data_type.upper(),
            "–Ø–∫—ñ—Å—Ç—å": result.quality_score,
            "–ü–æ–º–∏–ª–∫–∏": len(result.errors),
            "–ü–æ–ø–µ—Ä–µ–¥–∂–µ–Ω–Ω—è": len(result.warnings),
            "–ß–∞—Å (—Å)": f"{result.processing_time:.2f}"
        })
    
    df = pd.DataFrame(table_data)
    st.dataframe(df, use_container_width=True)
    
    # –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
    st.subheader("üìä –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤")
    
    col1, col2 = st.columns(2)
    
    with col1:
        # –†–æ–∑–ø–æ–¥—ñ–ª –æ—Ü—ñ–Ω–æ–∫ —è–∫–æ—Å—Ç—ñ
        quality_scores = [result.quality_score for _, result in results]
        fig = px.histogram(x=quality_scores, nbins=10, 
                          title="–†–æ–∑–ø–æ–¥—ñ–ª –æ—Ü—ñ–Ω–æ–∫ —è–∫–æ—Å—Ç—ñ",
                          labels={'x': '–û—Ü—ñ–Ω–∫–∞ —è–∫–æ—Å—Ç—ñ', 'y': '–ö—ñ–ª—å–∫—ñ—Å—Ç—å —Ñ–∞–π–ª—ñ–≤'})
        st.plotly_chart(fig, use_container_width=True)
    
    with col2:
        # –†–æ–∑–ø–æ–¥—ñ–ª —Ñ–æ—Ä–º–∞—Ç—ñ–≤
        formats = [f"{result.format_type.upper()} {result.version}" for _, result in results]
        format_counts = pd.Series(formats).value_counts()
        fig = px.pie(values=format_counts.values, names=format_counts.index,
                    title="–†–æ–∑–ø–æ–¥—ñ–ª —Ñ–æ—Ä–º–∞—Ç—ñ–≤ SBOM")
        st.plotly_chart(fig, use_container_width=True)
    
    # –ï–∫—Å–ø–æ—Ä—Ç –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–≤—ñ—Ç—É
    st.subheader("üì§ –ï–∫—Å–ø–æ—Ä—Ç –ø–∞–∫–µ—Ç–Ω–æ–≥–æ –∑–≤—ñ—Ç—É")
    
    batch_report = {
        "timestamp": datetime.now().isoformat(),
        "summary": {
            "total_files": total_files,
            "valid_files": valid_files,
            "invalid_files": total_files - valid_files,
            "average_quality": avg_quality
        },
        "results": [
            {
                "filename": filename,
                "is_valid": result.is_valid,
                "format_type": result.format_type,
                "version": result.version,
                "quality_score": result.quality_score,
                "errors": result.errors,
                "warnings": result.warnings
            }
            for filename, result in results
        ]
    }
    
    report_json = json.dumps(batch_report, indent=2, ensure_ascii=False)
    st.download_button(
        "üíæ –ó–∞–≤–∞–Ω—Ç–∞–∂–∏—Ç–∏ –ø–∞–∫–µ—Ç–Ω–∏–π –∑–≤—ñ—Ç",
        report_json,
        file_name=f"batch_validation_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json",
        mime="application/json"
    )

def show_schema_browser(validator):
    st.header("üìã –ë—Ä–∞—É–∑–µ—Ä —Å—Ö–µ–º SBOM")
    
    st.markdown("""
    –Ü–Ω—Ç–µ—Ä–∞–∫—Ç–∏–≤–Ω–∏–π –ø–µ—Ä–µ–≥–ª—è–¥ –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏—Ö —Å—Ö–µ–º –¥–ª—è SPDX —Ç–∞ CycloneDX —Ñ–æ—Ä–º–∞—Ç—ñ–≤.
    """)
    
    # –í–∏–±—ñ—Ä —Ñ–æ—Ä–º–∞—Ç—É —Ç–∞ –≤–µ—Ä—Å—ñ—ó
    col1, col2 = st.columns(2)
    
    with col1:
        format_type = st.selectbox(
            "–§–æ—Ä–º–∞—Ç:",
            ["spdx", "cyclonedx"],
            format_func=lambda x: x.upper()
        )
    
    with col2:
        versions = list(validator.supported_formats[format_type].keys())
        version = st.selectbox("–í–µ—Ä—Å—ñ—è:", versions)
    
    # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Å—Ö–µ–º–∏
    st.subheader(f"üìÑ –°—Ö–µ–º–∞ {format_type.upper()} {version}")
    
    if format_type == "spdx":
        if version == "2.3":
            schema = validator.spdx_schema_2_3
        elif version == "3.0":
            schema = validator.spdx_schema_3_0
        else:
            schema = {"error": "–°—Ö–µ–º–∞ –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–∞"}
    elif format_type == "cyclonedx":
        schema = validator.cyclonedx_schema
    
    # –í—ñ–¥–æ–±—Ä–∞–∂–µ–Ω–Ω—è —Å—Ö–µ–º–∏ —É —Ñ–æ—Ä–º–∞—Ç—ñ JSON
    st.json(schema)
    
    # –ü—Ä–∏–∫–ª–∞–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏
    st.subheader("üí° –ü—Ä–∏–∫–ª–∞–¥ —Å—Ç—Ä—É–∫—Ç—É—Ä–∏")
    
    if format_type == "spdx" and version == "2.3":
        example = {
            "spdxVersion": "SPDX-2.3",
            "SPDXID": "SPDXRef-DOCUMENT",
            "name": "Example SBOM",
            "dataLicense": "CC0-1.0",
            "packages": [
                {
                    "SPDXID": "SPDXRef-Package-1",
                    "name": "example-package",
                    "versionInfo": "1.0.0",
                    "licenseConcluded": "MIT"
                }
            ]
        }
    elif format_type == "cyclonedx":
        example = {
            "bomFormat": "CycloneDX",
            "specVersion": version,
            "version": 1,
            "metadata": {
                "timestamp": "2024-01-01T00:00:00Z",
                "tools": [
                    {"name": "enhanced-sbom-validator", "version": "1.0.0"}
                ]
            },
            "components": [
                {
                    "type": "library",
                    "name": "example-library",
                    "version": "2.1.0",
                    "licenses": [
                        {"license": {"id": "Apache-2.0"}}
                    ]
                }
            ]
        }
    
    st.json(example)

def show_examples_page(validator):
    st.header("üìù –ü—Ä–∏–∫–ª–∞–¥–∏ —Ç–∞ —Ç–µ—Å—Ç–∏")
    
    st.markdown("""
    –ì–æ—Ç–æ–≤—ñ –ø—Ä–∏–∫–ª–∞–¥–∏ SBOM —Ñ–∞–π–ª—ñ–≤ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è –≤–∞–ª—ñ–¥–∞—Ç–æ—Ä–∞.
    """)
    
    # –í–∏–±—ñ—Ä –ø—Ä–∏–∫–ª–∞–¥—É
    example_type = st.selectbox(
        "–í–∏–±–µ—Ä—ñ—Ç—å –ø—Ä–∏–∫–ª–∞–¥:",
        [
            "CycloneDX 1.4 - –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π",
            "CycloneDX 1.4 - –ü–æ–≤–Ω–∏–π",
            "SPDX 2.3 - –ë–∞–∑–æ–≤–∏–π",
            "CycloneDX 1.4 - –ó –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç—è–º–∏",
            "–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π JSON",
            "–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞"
        ]
    )
    
    examples = get_test_examples()
    
    if example_type in examples:
        example_content = examples[example_type]
        
        st.subheader(f"üìÑ –ü—Ä–∏–∫–ª–∞–¥: {example_type}")
        st.code(example_content, language="json")
        
        # –ö–Ω–æ–ø–∫–∞ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        if st.button(f"üß™ –¢–µ—Å—Ç—É–≤–∞—Ç–∏ {example_type}"):
            with st.spinner('–¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è...'):
                result = validator.validate(example_content, f"example_{example_type.lower()}.json", "comprehensive")
            
            display_validation_results(result, False, example_content)

def get_test_examples():
    """–ü–æ–≤–µ—Ä—Ç–∞—î —Å–ª–æ–≤–Ω–∏–∫ –∑ —Ç–µ—Å—Ç–æ–≤–∏–º–∏ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏"""
    return {
        "CycloneDX 1.4 - –ú—ñ–Ω—ñ–º–∞–ª—å–Ω–∏–π": json.dumps({
            "bomFormat": "CycloneDX",
            "specVersion": "1.4",
            "version": 1,
            "components": []
        }, indent=2),
        
        "CycloneDX 1.4 - –ü–æ–≤–Ω–∏–π": json.dumps({
            "bomFormat": "CycloneDX",
            "specVersion": "1.4",
            "version": 1,
            "metadata": {
                "timestamp": "2024-01-01T12:00:00Z",
                "tools": [
                    {"name": "enhanced-sbom-validator", "version": "1.0.0"}
                ],
                "authors": [
                    {"name": "SBOM Generator", "email": "sbom@example.com"}
                ],
                "component": {
                    "type": "application",
                    "name": "my-application",
                    "version": "1.0.0"
                }
            },
            "components": [
                {
                    "type": "library",
                    "name": "lodash",
                    "version": "4.17.21",
                    "licenses": [
                        {"license": {"id": "MIT"}}
                    ],
                    "purl": "pkg:npm/lodash@4.17.21"
                },
                {
                    "type": "library", 
                    "name": "react",
                    "version": "18.2.0",
                    "licenses": [
                        {"license": {"id": "MIT"}}
                    ],
                    "purl": "pkg:npm/react@18.2.0"
                }
            ],
            "dependencies": [
                {
                    "ref": "pkg:npm/my-application@1.0.0",
                    "dependsOn": [
                        "pkg:npm/lodash@4.17.21",
                        "pkg:npm/react@18.2.0"
                    ]
                }
            ]
        }, indent=2),
        
        "SPDX 2.3 - –ë–∞–∑–æ–≤–∏–π": json.dumps({
            "spdxVersion": "SPDX-2.3",
            "SPDXID": "SPDXRef-DOCUMENT",
            "name": "Example SBOM Document",
            "dataLicense": "CC0-1.0",
            "creationInfo": {
                "created": "2024-01-01T12:00:00Z",
                "creators": ["Tool: enhanced-sbom-validator"]
            },
            "packages": [
                {
                    "SPDXID": "SPDXRef-Package-lodash",
                    "name": "lodash",
                    "versionInfo": "4.17.21",
                    "licenseConcluded": "MIT",
                    "downloadLocation": "https://registry.npmjs.org/lodash/-/lodash-4.17.21.tgz"
                }
            ]
        }, indent=2),
        
        "CycloneDX 1.4 - –ó –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç—è–º–∏": json.dumps({
            "bomFormat": "CycloneDX",
            "specVersion": "1.4", 
            "version": 1,
            "components": [
                {
                    "type": "library",
                    "name": "vulnerable-lib",
                    "version": "1.0.0",
                    "licenses": [
                        {"license": {"id": "MIT"}}
                    ],
                    "vulnerabilities": [
                        {
                            "id": "CVE-2023-12345",
                            "severity": "high",
                            "description": "Example vulnerability"
                        },
                        {
                            "id": "CVE-2023-67890", 
                            "severity": "critical",
                            "description": "Critical security issue"
                        }
                    ]
                }
            ]
        }, indent=2),
        
        "–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∏–π JSON": '{"bomFormat": "CycloneDX", "specVersion": "1.4", "version": 1, "components": [}',
        
        "–ù–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞": json.dumps({
            "bomFormat": "CycloneDX",
            "specVersion": "1.4"
            # –í—ñ–¥—Å—É—Ç–Ω—ñ –æ–±–æ–≤'—è–∑–∫–æ–≤—ñ –ø–æ–ª—è
        }, indent=2)
    }

def show_advanced_analysis(validator):
    st.header("üîç –†–æ–∑—à–∏—Ä–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ SBOM")
    
    st.markdown("""
    –ì–ª–∏–±–æ–∫–∏–π –∞–Ω–∞–ª—ñ–∑ SBOM –¥–æ–∫—É–º–µ–Ω—Ç—ñ–≤ –∑ —Ñ–æ–∫—É—Å–æ–º –Ω–∞ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ, –ª—ñ—Ü–µ–Ω–∑—ñ—ó —Ç–∞ –±–µ–∑–ø–µ–∫—É.
    """)
    
    uploaded_file = st.file_uploader(
        "–ó–∞–≤–∞–Ω—Ç–∞–∂—Ç–µ SBOM –¥–ª—è —Ä–æ–∑—à–∏—Ä–µ–Ω–æ–≥–æ –∞–Ω–∞–ª—ñ–∑—É",
        type=['json', 'xml']
    )
    
    if uploaded_file:
        content = uploaded_file.read().decode('utf-8')
        
        with st.spinner('–í–∏–∫–æ–Ω—É—î—Ç—å—Å—è —Ä–æ–∑—à–∏—Ä–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑...'):
            result = validator.validate(content, uploaded_file.name, "comprehensive")
        
        if result.analysis:
            st.success("‚úÖ –ê–Ω–∞–ª—ñ–∑ –∑–∞–≤–µ—Ä—à–µ–Ω–æ")
            
            # –î–µ—Ç–∞–ª—å–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π
            if "dependency_analysis" in result.analysis:
                st.subheader("üï∏Ô∏è –ì—Ä–∞—Ñ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π")
                deps = result.analysis["dependency_analysis"]
                
                # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó –≥—Ä–∞—Ñ–∞ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π
                if deps.get("total_dependencies", 0) > 0:
                    # –¢—É—Ç –º–æ–∂–Ω–∞ –¥–æ–¥–∞—Ç–∏ –±—ñ–ª—å—à —Å–∫–ª–∞–¥–Ω—É –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—é –≥—Ä–∞—Ñ–∞
                    st.info("üìä –í—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—è –≥—Ä–∞—Ñ–∞ –∑–∞–ª–µ–∂–Ω–æ—Å—Ç–µ–π –±—É–¥–µ –¥–æ–¥–∞–Ω–∞ –≤ –Ω–∞—Å—Ç—É–ø–Ω—ñ–π –≤–µ—Ä—Å—ñ—ó")
                
                # –ê–Ω–∞–ª—ñ–∑ –≥–ª–∏–±–∏–Ω–∏ —Ç–∞ —Å–∫–ª–∞–¥–Ω–æ—Å—Ç—ñ
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("üìè –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–∞ –≥–ª–∏–±–∏–Ω–∞", deps.get("dependency_graph_depth", 0))
                with col2:
                    st.metric("üå≥ –ö–æ—Ä–µ–Ω–µ–≤—ñ –≤—É–∑–ª–∏", len(deps.get("root_components", [])))
                with col3:
                    st.metric("üçÉ –õ–∏—Å—Ç–æ–≤—ñ –≤—É–∑–ª–∏", len(deps.get("leaf_components", [])))
            
            # –ê–Ω–∞–ª—ñ–∑ –ª—ñ—Ü–µ–Ω–∑—ñ–π–Ω–æ–≥–æ —Ä–∏–∑–∏–∫—É
            if "license_analysis" in result.analysis:
                st.subheader("‚öñÔ∏è –õ—ñ—Ü–µ–Ω–∑—ñ–π–Ω–∏–π —Ä–∏–∑–∏–∫")
                licenses = result.analysis["license_analysis"]
                
                # –ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –ª—ñ—Ü–µ–Ω–∑—ñ–π –∑–∞ —Ä—ñ–≤–Ω–µ–º —Ä–∏–∑–∏–∫—É
                license_risk = classify_license_risk(licenses.get("distribution", {}))
                
                if license_risk:
                    risk_df = pd.DataFrame(list(license_risk.items()), 
                                         columns=["–†—ñ–≤–µ–Ω—å —Ä–∏–∑–∏–∫—É", "–ö—ñ–ª—å–∫—ñ—Å—Ç—å"])
                    
                    colors = {"–ù–∏–∑—å–∫–∏–π": "green", "–°–µ—Ä–µ–¥–Ω—ñ–π": "orange", "–í–∏—Å–æ–∫–∏–π": "red", "–ù–µ–≤—ñ–¥–æ–º–∏–π": "gray"}
                    fig = px.bar(risk_df, x="–†—ñ–≤–µ–Ω—å —Ä–∏–∑–∏–∫—É", y="–ö—ñ–ª—å–∫—ñ—Å—Ç—å",
                               color="–†—ñ–≤–µ–Ω—å —Ä–∏–∑–∏–∫—É", color_discrete_map=colors,
                               title="–†–æ–∑–ø–æ–¥—ñ–ª –ª—ñ—Ü–µ–Ω–∑—ñ–π –∑–∞ —Ä—ñ–≤–Ω–µ–º —Ä–∏–∑–∏–∫—É")
                    st.plotly_chart(fig, use_container_width=True)
            
            # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
            st.subheader("üí° –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó")
            generate_recommendations(result)
        else:
            st.warning("‚ö†Ô∏è –†–æ–∑—à–∏—Ä–µ–Ω–∏–π –∞–Ω–∞–ª—ñ–∑ –Ω–µ –¥–æ—Å—Ç—É–ø–Ω–∏–π –¥–ª—è —Ü—å–æ–≥–æ —Ç–∏–ø—É SBOM")

def classify_license_risk(license_distribution: Dict[str, int]) -> Dict[str, int]:
    """–ö–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è –ª—ñ—Ü–µ–Ω–∑—ñ–π –∑–∞ —Ä—ñ–≤–Ω–µ–º —Ä–∏–∑–∏–∫—É"""
    risk_classification = {
        "–ù–∏–∑—å–∫–∏–π": ["MIT", "Apache-2.0", "BSD-3-Clause", "BSD-2-Clause", "ISC"],
        "–°–µ—Ä–µ–¥–Ω—ñ–π": ["GPL-2.0", "GPL-3.0", "LGPL-2.1", "LGPL-3.0", "MPL-2.0"],
        "–í–∏—Å–æ–∫–∏–π": ["AGPL-3.0", "GPL-2.0-only", "GPL-3.0-only"],
        "–ù–µ–≤—ñ–¥–æ–º–∏–π": ["NOASSERTION", "Unknown"]
    }
    
    risk_counts = {"–ù–∏–∑—å–∫–∏–π": 0, "–°–µ—Ä–µ–¥–Ω—ñ–π": 0, "–í–∏—Å–æ–∫–∏–π": 0, "–ù–µ–≤—ñ–¥–æ–º–∏–π": 0}
    
    for license_id, count in license_distribution.items():
        classified = False
        for risk_level, licenses in risk_classification.items():
            if license_id in licenses:
                risk_counts[risk_level] += count
                classified = True
                break
        
        if not classified:
            risk_counts["–ù–µ–≤—ñ–¥–æ–º–∏–π"] += count
    
    return risk_counts

def generate_recommendations(result: ValidationResult):
    """–ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ–π –Ω–∞ –æ—Å–Ω–æ–≤—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ñ–≤ –∞–Ω–∞–ª—ñ–∑—É"""
    recommendations = []
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ –ø–æ–º–∏–ª–æ–∫
    if result.errors:
        recommendations.append("üî¥ **–ö—Ä–∏—Ç–∏—á–Ω–æ**: –í–∏–ø—Ä–∞–≤—Ç–µ –≤—Å—ñ –ø–æ–º–∏–ª–∫–∏ –≤–∞–ª—ñ–¥–∞—Ü—ñ—ó –ø–µ—Ä–µ–¥ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º SBOM")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ —è–∫–æ—Å—Ç—ñ
    if result.quality_score < 60:
        recommendations.append("üü° **–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è —è–∫–æ—Å—Ç—ñ**: –î–æ–¥–∞–π—Ç–µ –±—ñ–ª—å—à–µ –º–µ—Ç–∞–¥–∞–Ω–∏—Ö —Ç–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—ó –ø—Ä–æ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏")
    
    # –†–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –Ω–∞ –æ—Å–Ω–æ–≤—ñ –∞–Ω–∞–ª—ñ–∑—É
    if result.analysis:
        # –õ—ñ—Ü–µ–Ω–∑—ñ—ó
        if "license_analysis" in result.analysis:
            unlicensed = result.analysis["license_analysis"].get("unlicensed_count", 0)
            if unlicensed > 0:
                recommendations.append(f"‚öñÔ∏è **–õ—ñ—Ü–µ–Ω–∑—ñ—ó**: –î–æ–¥–∞–π—Ç–µ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—é –ø—Ä–æ –ª—ñ—Ü–µ–Ω–∑—ñ—ó –¥–ª—è {unlicensed} –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤")
        
        # –ë–µ–∑–ø–µ–∫–∞
        if "security_analysis" in result.analysis:
            critical_vulns = result.analysis["security_analysis"].get("critical_count", 0)
            if critical_vulns > 0:
                recommendations.append(f"üö® **–ë–µ–∑–ø–µ–∫–∞**: –ó–Ω–∞–π–¥–µ–Ω–æ {critical_vulns} –∫—Ä–∏—Ç–∏—á–Ω–∏—Ö –≤—Ä–∞–∑–ª–∏–≤–æ—Å—Ç–µ–π - –Ω–µ–≥–∞–π–Ω–æ –æ–Ω–æ–≤—ñ—Ç—å –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏")
        
        # –í–µ—Ä—Å—ñ—ó
        if "component_stats" in result.analysis:
            stats = result.analysis["component_stats"]
            total = stats.get("total_components", stats.get("total_packages", 0))
            with_versions = stats.get("with_versions", 0)
            if total > 0 and (with_versions / total) < 0.8:
                recommendations.append("üî¢ **–í–µ—Ä—Å—ñ—ó**: –î–æ–¥–∞–π—Ç–µ –Ω–æ–º–µ—Ä–∏ –≤–µ—Ä—Å—ñ–π –¥–ª—è –≤—Å—ñ—Ö –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ñ–≤")
    
    # –ó–∞–≥–∞–ª—å–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
    if result.quality_score >= 80:
        recommendations.append("‚úÖ **–í—ñ–¥–º—ñ–Ω–Ω–æ**: SBOM –≤—ñ–¥–ø–æ–≤—ñ–¥–∞—î –≤–∏—Å–æ–∫–∏–º —Å—Ç–∞–Ω–¥–∞—Ä—Ç–∞–º —è–∫–æ—Å—Ç—ñ")
    
    if not recommendations:
        recommendations.append("‚úÖ **–ì–∞—Ä–Ω–∞ —Ä–æ–±–æ—Ç–∞**: –û—Å–Ω–æ–≤–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó –≤—ñ–¥—Å—É—Ç–Ω—ñ")
    
    for rec in recommendations:
        st.markdown(rec)

def show_support_matrix(validator):
    st.header("üìà –ú–∞—Ç—Ä–∏—Ü—è –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ —Ñ–æ—Ä–º–∞—Ç—ñ–≤")
    
    st.markdown("""
    –ü–æ–≤–Ω–∞ —Ç–∞–±–ª–∏—Ü—è –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏—Ö —Ñ–æ—Ä–º–∞—Ç—ñ–≤, –≤–µ—Ä—Å—ñ–π —Ç–∞ —Ç–∏–ø—ñ–≤ —Ñ–∞–π–ª—ñ–≤.
    """)
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è —Ç–∞–±–ª–∏—Ü—ñ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏
    support_data = []
    
    for format_name, versions in validator.supported_formats.items():
        for version, data_types in versions.items():
            for data_type, supported in data_types.items():
                status = "‚úÖ –ü—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è" if supported else "‚ùå –ù–µ –ø—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è"
                support_data.append({
                    "–§–æ—Ä–º–∞—Ç": format_name.upper(),
                    "–í–µ—Ä—Å—ñ—è": version,
                    "–¢–∏–ø —Ñ–∞–π–ª—É": data_type.upper(),
                    "–°—Ç–∞—Ç—É—Å": status,
                    "–í–∞–ª—ñ–¥–∞—Ü—ñ—è —Å—Ö–µ–º–∏": "‚úÖ" if supported else "‚ùå",
                    "–ë—ñ–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞": "‚úÖ" if supported else "‚ùå",
                    "–°–µ–º–∞–Ω—Ç–∏—á–Ω–∏–π –∞–Ω–∞–ª—ñ–∑": "‚úÖ" if supported and format_name == "cyclonedx" else "‚ö†Ô∏è"
                })
    
    df = pd.DataFrame(support_data)
    st.dataframe(df, use_container_width=True)
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏
    st.subheader("üìä –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        total_combinations = len(support_data)
        supported_combinations = len([d for d in support_data if "‚úÖ" in d["–°—Ç–∞—Ç—É—Å"]])
        st.metric("üìã –í—Å—å–æ–≥–æ –∫–æ–º–±—ñ–Ω–∞—Ü—ñ–π", total_combinations)
        st.metric("‚úÖ –ü—ñ–¥—Ç—Ä–∏–º—É—î—Ç—å—Å—è", supported_combinations)
    
    with col2:
        formats_count = len(validator.supported_formats)
        versions_count = sum(len(versions) for versions in validator.supported_formats.values())
        st.metric("üìö –§–æ—Ä–º–∞—Ç—ñ–≤", formats_count)
        st.metric("üî¢ –í–µ—Ä—Å—ñ–π", versions_count)
    
    with col3:
        json_support = len([d for d in support_data if d["–¢–∏–ø —Ñ–∞–π–ª—É"] == "JSON" and "‚úÖ" in d["–°—Ç–∞—Ç—É—Å"]])
        xml_support = len([d for d in support_data if d["–¢–∏–ø —Ñ–∞–π–ª—É"] == "XML" and "‚úÖ" in d["–°—Ç–∞—Ç—É—Å"]])
        st.metric("üìÑ JSON –ø—ñ–¥—Ç—Ä–∏–º–∫–∞", json_support)
        st.metric("üè∑Ô∏è XML –ø—ñ–¥—Ç—Ä–∏–º–∫–∞", xml_support)
    
    # –î—ñ–∞–≥—Ä–∞–º–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏
    format_counts = df.groupby("–§–æ—Ä–º–∞—Ç").size()
    fig = px.bar(x=format_counts.index, y=format_counts.values,
                title="–ö—ñ–ª—å–∫—ñ—Å—Ç—å –ø—ñ–¥—Ç—Ä–∏–º—É–≤–∞–Ω–∏—Ö –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤ –∑–∞ —Ñ–æ—Ä–º–∞—Ç–∞–º–∏",
                labels={'x': '–§–æ—Ä–º–∞—Ç', 'y': '–ö—ñ–ª—å–∫—ñ—Å—Ç—å –≤–∞—Ä—ñ–∞–Ω—Ç—ñ–≤'})
    st.plotly_chart(fig, use_container_width=True)
    
    # –î–µ—Ç–∞–ª—å–Ω–∞ —ñ–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ
    st.subheader("üîç –î–µ—Ç–∞–ª—å–Ω—ñ –º–æ–∂–ª–∏–≤–æ—Å—Ç—ñ")
    
    capabilities = {
        "Auto-Detection": {
            "SPDX JSON": "‚úÖ –ü–æ–≤–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞",
            "CycloneDX JSON": "‚úÖ –ü–æ–≤–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞", 
            "CycloneDX XML": "‚úÖ –ü–æ–≤–Ω–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞",
            "SPDX XML": "‚ö†Ô∏è –ë–∞–∑–æ–≤–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∞"
        },
        "–í–∞–ª—ñ–¥–∞—Ü—ñ—è —Å—Ö–µ–º–∏": {
            "JSON Schema": "‚úÖ JSONSchema validation",
            "XML Schema": "‚úÖ XSD validation",
            "–ë—ñ–∑–Ω–µ—Å-–ø—Ä–∞–≤–∏–ª–∞": "‚úÖ Custom validation rules",
            "–°–µ–º–∞–Ω—Ç–∏—á–Ω–∞ –≤–∞–ª—ñ–¥–∞—Ü—ñ—è": "‚úÖ Deep structure analysis"
        },
        "–ê–Ω–∞–ª—ñ—Ç–∏–∫–∞": {
            "–ö–æ–º–ø–æ–Ω–µ–Ω—Ç–∏": "‚úÖ –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —Ç–∞ —Ç–∏–ø–∏",
            "–ó–∞–ª–µ–∂–Ω–æ—Å—Ç—ñ": "‚úÖ –ì—Ä–∞—Ñ —Ç–∞ –≥–ª–∏–±–∏–Ω–∞",
            "–õ—ñ—Ü–µ–Ω–∑—ñ—ó": "‚úÖ –†–æ–∑–ø–æ–¥—ñ–ª —Ç–∞ —Ä–∏–∑–∏–∫–∏",
            "–ë–µ–∑–ø–µ–∫–∞": "‚úÖ –í—Ä–∞–∑–ª–∏–≤–æ—Å—Ç—ñ —Ç–∞ —Ä—ñ–≤–Ω—ñ"
        },
        "–ï–∫—Å–ø–æ—Ä—Ç": {
            "JSON –∑–≤—ñ—Ç–∏": "‚úÖ –°—Ç—Ä—É–∫—Ç—É—Ä–æ–≤–∞–Ω—ñ –¥–∞–Ω—ñ",
            "CSV –µ–∫—Å–ø–æ—Ä—Ç": "‚ö†Ô∏è –ü–ª–∞–Ω—É—î—Ç—å—Å—è",
            "PDF –∑–≤—ñ—Ç–∏": "‚ö†Ô∏è –ü–ª–∞–Ω—É—î—Ç—å—Å—è", 
            "API —ñ–Ω—Ç–µ–≥—Ä–∞—Ü—ñ—è": "‚ö†Ô∏è –ü–ª–∞–Ω—É—î—Ç—å—Å—è"
        }
    }
    
    for category, features in capabilities.items():
        with st.expander(f"üìã {category}"):
            for feature, status in features.items():
                st.markdown(f"- **{feature}**: {status}")

if __name__ == "__main__":
    main()